{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17cfb44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b310e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local').appName('ML').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6daf4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('sonar_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0866ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+----+\n",
      "|   _c0|   _c1|   _c2|   _c3|   _c4|   _c5|   _c6|   _c7|   _c8|   _c9|  _c10|  _c11|  _c12|  _c13|  _c14|  _c15|  _c16|  _c17|  _c18|  _c19|  _c20|  _c21|  _c22|  _c23|  _c24|  _c25|  _c26|  _c27|  _c28|  _c29|  _c30|  _c31|  _c32|  _c33|  _c34|  _c35|  _c36|  _c37|  _c38|  _c39|  _c40|  _c41|  _c42|  _c43|  _c44|  _c45|  _c46|  _c47|  _c48|  _c49|  _c50|  _c51|  _c52|  _c53|  _c54|  _c55|  _c56|  _c57|  _c58|  _c59|_c60|\n",
      "+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+----+\n",
      "|0.0200|0.0371|0.0428|0.0207|0.0954|0.0986|0.1539|0.1601|0.3109|0.2111|0.1609|0.1582|0.2238|0.0645|0.0660|0.2273|0.3100|0.2999|0.5078|0.4797|0.5783|0.5071|0.4328|0.5550|0.6711|0.6415|0.7104|0.8080|0.6791|0.3857|0.1307|0.2604|0.5121|0.7547|0.8537|0.8507|0.6692|0.6097|0.4943|0.2744|0.0510|0.2834|0.2825|0.4256|0.2641|0.1386|0.1051|0.1343|0.0383|0.0324|0.0232|0.0027|0.0065|0.0159|0.0072|0.0167|0.0180|0.0084|0.0090|0.0032|   R|\n",
      "|0.0453|0.0523|0.0843|0.0689|0.1183|0.2583|0.2156|0.3481|0.3337|0.2872|0.4918|0.6552|0.6919|0.7797|0.7464|0.9444|1.0000|0.8874|0.8024|0.7818|0.5212|0.4052|0.3957|0.3914|0.3250|0.3200|0.3271|0.2767|0.4423|0.2028|0.3788|0.2947|0.1984|0.2341|0.1306|0.4182|0.3835|0.1057|0.1840|0.1970|0.1674|0.0583|0.1401|0.1628|0.0621|0.0203|0.0530|0.0742|0.0409|0.0061|0.0125|0.0084|0.0089|0.0048|0.0094|0.0191|0.0140|0.0049|0.0052|0.0044|   R|\n",
      "|0.0262|0.0582|0.1099|0.1083|0.0974|0.2280|0.2431|0.3771|0.5598|0.6194|0.6333|0.7060|0.5544|0.5320|0.6479|0.6931|0.6759|0.7551|0.8929|0.8619|0.7974|0.6737|0.4293|0.3648|0.5331|0.2413|0.5070|0.8533|0.6036|0.8514|0.8512|0.5045|0.1862|0.2709|0.4232|0.3043|0.6116|0.6756|0.5375|0.4719|0.4647|0.2587|0.2129|0.2222|0.2111|0.0176|0.1348|0.0744|0.0130|0.0106|0.0033|0.0232|0.0166|0.0095|0.0180|0.0244|0.0316|0.0164|0.0095|0.0078|   R|\n",
      "|0.0100|0.0171|0.0623|0.0205|0.0205|0.0368|0.1098|0.1276|0.0598|0.1264|0.0881|0.1992|0.0184|0.2261|0.1729|0.2131|0.0693|0.2281|0.4060|0.3973|0.2741|0.3690|0.5556|0.4846|0.3140|0.5334|0.5256|0.2520|0.2090|0.3559|0.6260|0.7340|0.6120|0.3497|0.3953|0.3012|0.5408|0.8814|0.9857|0.9167|0.6121|0.5006|0.3210|0.3202|0.4295|0.3654|0.2655|0.1576|0.0681|0.0294|0.0241|0.0121|0.0036|0.0150|0.0085|0.0073|0.0050|0.0044|0.0040|0.0117|   R|\n",
      "|0.0762|0.0666|0.0481|0.0394|0.0590|0.0649|0.1209|0.2467|0.3564|0.4459|0.4152|0.3952|0.4256|0.4135|0.4528|0.5326|0.7306|0.6193|0.2032|0.4636|0.4148|0.4292|0.5730|0.5399|0.3161|0.2285|0.6995|1.0000|0.7262|0.4724|0.5103|0.5459|0.2881|0.0981|0.1951|0.4181|0.4604|0.3217|0.2828|0.2430|0.1979|0.2444|0.1847|0.0841|0.0692|0.0528|0.0357|0.0085|0.0230|0.0046|0.0156|0.0031|0.0054|0.0105|0.0110|0.0015|0.0072|0.0048|0.0107|0.0094|   R|\n",
      "|0.0286|0.0453|0.0277|0.0174|0.0384|0.0990|0.1201|0.1833|0.2105|0.3039|0.2988|0.4250|0.6343|0.8198|1.0000|0.9988|0.9508|0.9025|0.7234|0.5122|0.2074|0.3985|0.5890|0.2872|0.2043|0.5782|0.5389|0.3750|0.3411|0.5067|0.5580|0.4778|0.3299|0.2198|0.1407|0.2856|0.3807|0.4158|0.4054|0.3296|0.2707|0.2650|0.0723|0.1238|0.1192|0.1089|0.0623|0.0494|0.0264|0.0081|0.0104|0.0045|0.0014|0.0038|0.0013|0.0089|0.0057|0.0027|0.0051|0.0062|   R|\n",
      "|0.0317|0.0956|0.1321|0.1408|0.1674|0.1710|0.0731|0.1401|0.2083|0.3513|0.1786|0.0658|0.0513|0.3752|0.5419|0.5440|0.5150|0.4262|0.2024|0.4233|0.7723|0.9735|0.9390|0.5559|0.5268|0.6826|0.5713|0.5429|0.2177|0.2149|0.5811|0.6323|0.2965|0.1873|0.2969|0.5163|0.6153|0.4283|0.5479|0.6133|0.5017|0.2377|0.1957|0.1749|0.1304|0.0597|0.1124|0.1047|0.0507|0.0159|0.0195|0.0201|0.0248|0.0131|0.0070|0.0138|0.0092|0.0143|0.0036|0.0103|   R|\n",
      "|0.0519|0.0548|0.0842|0.0319|0.1158|0.0922|0.1027|0.0613|0.1465|0.2838|0.2802|0.3086|0.2657|0.3801|0.5626|0.4376|0.2617|0.1199|0.6676|0.9402|0.7832|0.5352|0.6809|0.9174|0.7613|0.8220|0.8872|0.6091|0.2967|0.1103|0.1318|0.0624|0.0990|0.4006|0.3666|0.1050|0.1915|0.3930|0.4288|0.2546|0.1151|0.2196|0.1879|0.1437|0.2146|0.2360|0.1125|0.0254|0.0285|0.0178|0.0052|0.0081|0.0120|0.0045|0.0121|0.0097|0.0085|0.0047|0.0048|0.0053|   R|\n",
      "|0.0223|0.0375|0.0484|0.0475|0.0647|0.0591|0.0753|0.0098|0.0684|0.1487|0.1156|0.1654|0.3833|0.3598|0.1713|0.1136|0.0349|0.3796|0.7401|0.9925|0.9802|0.8890|0.6712|0.4286|0.3374|0.7366|0.9611|0.7353|0.4856|0.1594|0.3007|0.4096|0.3170|0.3305|0.3408|0.2186|0.2463|0.2726|0.1680|0.2792|0.2558|0.1740|0.2121|0.1099|0.0985|0.1271|0.1459|0.1164|0.0777|0.0439|0.0061|0.0145|0.0128|0.0145|0.0058|0.0049|0.0065|0.0093|0.0059|0.0022|   R|\n",
      "|0.0164|0.0173|0.0347|0.0070|0.0187|0.0671|0.1056|0.0697|0.0962|0.0251|0.0801|0.1056|0.1266|0.0890|0.0198|0.1133|0.2826|0.3234|0.3238|0.4333|0.6068|0.7652|0.9203|0.9719|0.9207|0.7545|0.8289|0.8907|0.7309|0.6896|0.5829|0.4935|0.3101|0.0306|0.0244|0.1108|0.1594|0.1371|0.0696|0.0452|0.0620|0.1421|0.1597|0.1384|0.0372|0.0688|0.0867|0.0513|0.0092|0.0198|0.0118|0.0090|0.0223|0.0179|0.0084|0.0068|0.0032|0.0035|0.0056|0.0040|   R|\n",
      "|0.0039|0.0063|0.0152|0.0336|0.0310|0.0284|0.0396|0.0272|0.0323|0.0452|0.0492|0.0996|0.1424|0.1194|0.0628|0.0907|0.1177|0.1429|0.1223|0.1104|0.1847|0.3715|0.4382|0.5707|0.6654|0.7476|0.7654|0.8555|0.9720|0.9221|0.7502|0.7209|0.7757|0.6055|0.5021|0.4499|0.3947|0.4281|0.4427|0.3749|0.1972|0.0511|0.0793|0.1269|0.1533|0.0690|0.0402|0.0534|0.0228|0.0073|0.0062|0.0062|0.0120|0.0052|0.0056|0.0093|0.0042|0.0003|0.0053|0.0036|   R|\n",
      "|0.0123|0.0309|0.0169|0.0313|0.0358|0.0102|0.0182|0.0579|0.1122|0.0835|0.0548|0.0847|0.2026|0.2557|0.1870|0.2032|0.1463|0.2849|0.5824|0.7728|0.7852|0.8515|0.5312|0.3653|0.5973|0.8275|1.0000|0.8673|0.6301|0.4591|0.3940|0.2576|0.2817|0.2641|0.2757|0.2698|0.3994|0.4576|0.3940|0.2522|0.1782|0.1354|0.0516|0.0337|0.0894|0.0861|0.0872|0.0445|0.0134|0.0217|0.0188|0.0133|0.0265|0.0224|0.0074|0.0118|0.0026|0.0092|0.0009|0.0044|   R|\n",
      "|0.0079|0.0086|0.0055|0.0250|0.0344|0.0546|0.0528|0.0958|0.1009|0.1240|0.1097|0.1215|0.1874|0.3383|0.3227|0.2723|0.3943|0.6432|0.7271|0.8673|0.9674|0.9847|0.9480|0.8036|0.6833|0.5136|0.3090|0.0832|0.4019|0.2344|0.1905|0.1235|0.1717|0.2351|0.2489|0.3649|0.3382|0.1589|0.0989|0.1089|0.1043|0.0839|0.1391|0.0819|0.0678|0.0663|0.1202|0.0692|0.0152|0.0266|0.0174|0.0176|0.0127|0.0088|0.0098|0.0019|0.0059|0.0058|0.0059|0.0032|   R|\n",
      "|0.0090|0.0062|0.0253|0.0489|0.1197|0.1589|0.1392|0.0987|0.0955|0.1895|0.1896|0.2547|0.4073|0.2988|0.2901|0.5326|0.4022|0.1571|0.3024|0.3907|0.3542|0.4438|0.6414|0.4601|0.6009|0.8690|0.8345|0.7669|0.5081|0.4620|0.5380|0.5375|0.3844|0.3601|0.7402|0.7761|0.3858|0.0667|0.3684|0.6114|0.3510|0.2312|0.2195|0.3051|0.1937|0.1570|0.0479|0.0538|0.0146|0.0068|0.0187|0.0059|0.0095|0.0194|0.0080|0.0152|0.0158|0.0053|0.0189|0.0102|   R|\n",
      "|0.0124|0.0433|0.0604|0.0449|0.0597|0.0355|0.0531|0.0343|0.1052|0.2120|0.1640|0.1901|0.3026|0.2019|0.0592|0.2390|0.3657|0.3809|0.5929|0.6299|0.5801|0.4574|0.4449|0.3691|0.6446|0.8940|0.8978|0.4980|0.3333|0.2350|0.1553|0.3666|0.4340|0.3082|0.3024|0.4109|0.5501|0.4129|0.5499|0.5018|0.3132|0.2802|0.2351|0.2298|0.1155|0.0724|0.0621|0.0318|0.0450|0.0167|0.0078|0.0083|0.0057|0.0174|0.0188|0.0054|0.0114|0.0196|0.0147|0.0062|   R|\n",
      "|0.0298|0.0615|0.0650|0.0921|0.1615|0.2294|0.2176|0.2033|0.1459|0.0852|0.2476|0.3645|0.2777|0.2826|0.3237|0.4335|0.5638|0.4555|0.4348|0.6433|0.3932|0.1989|0.3540|0.9165|0.9371|0.4620|0.2771|0.6613|0.8028|0.4200|0.5192|0.6962|0.5792|0.8889|0.7863|0.7133|0.7615|0.4401|0.3009|0.3163|0.2809|0.2898|0.0526|0.1867|0.1553|0.1633|0.1252|0.0748|0.0452|0.0064|0.0154|0.0031|0.0153|0.0071|0.0212|0.0076|0.0152|0.0049|0.0200|0.0073|   R|\n",
      "|0.0352|0.0116|0.0191|0.0469|0.0737|0.1185|0.1683|0.1541|0.1466|0.2912|0.2328|0.2237|0.2470|0.1560|0.3491|0.3308|0.2299|0.2203|0.2493|0.4128|0.3158|0.6191|0.5854|0.3395|0.2561|0.5599|0.8145|0.6941|0.6985|0.8660|0.5930|0.3664|0.6750|0.8697|0.7837|0.7552|0.5789|0.4713|0.1252|0.6087|0.7322|0.5977|0.3431|0.1803|0.2378|0.3424|0.2303|0.0689|0.0216|0.0469|0.0426|0.0346|0.0158|0.0154|0.0109|0.0048|0.0095|0.0015|0.0073|0.0067|   R|\n",
      "|0.0192|0.0607|0.0378|0.0774|0.1388|0.0809|0.0568|0.0219|0.1037|0.1186|0.1237|0.1601|0.3520|0.4479|0.3769|0.5761|0.6426|0.6790|0.7157|0.5466|0.5399|0.6362|0.7849|0.7756|0.5780|0.4862|0.4181|0.2457|0.0716|0.0613|0.1816|0.4493|0.5976|0.3785|0.2495|0.5771|0.8852|0.8409|0.3570|0.3133|0.6096|0.6378|0.2709|0.1419|0.1260|0.1288|0.0790|0.0829|0.0520|0.0216|0.0360|0.0331|0.0131|0.0120|0.0108|0.0024|0.0045|0.0037|0.0112|0.0075|   R|\n",
      "|0.0270|0.0092|0.0145|0.0278|0.0412|0.0757|0.1026|0.1138|0.0794|0.1520|0.1675|0.1370|0.1361|0.1345|0.2144|0.5354|0.6830|0.5600|0.3093|0.3226|0.4430|0.5573|0.5782|0.6173|0.8132|0.9819|0.9823|0.9166|0.7423|0.7736|0.8473|0.7352|0.6671|0.6083|0.6239|0.5972|0.5715|0.5242|0.2924|0.1536|0.2003|0.2031|0.2207|0.1778|0.1353|0.1373|0.0749|0.0472|0.0325|0.0179|0.0045|0.0084|0.0010|0.0018|0.0068|0.0039|0.0120|0.0132|0.0070|0.0088|   R|\n",
      "|0.0126|0.0149|0.0641|0.1732|0.2565|0.2559|0.2947|0.4110|0.4983|0.5920|0.5832|0.5419|0.5472|0.5314|0.4981|0.6985|0.8292|0.7839|0.8215|0.9363|1.0000|0.9224|0.7839|0.5470|0.4562|0.5922|0.5448|0.3971|0.0882|0.2385|0.2005|0.0587|0.2544|0.2009|0.0329|0.1547|0.1212|0.2446|0.3171|0.3195|0.3051|0.0836|0.1266|0.1381|0.1136|0.0516|0.0073|0.0278|0.0372|0.0121|0.0153|0.0092|0.0035|0.0098|0.0121|0.0006|0.0181|0.0094|0.0116|0.0063|   R|\n",
      "+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ce119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "      <th>_c2</th>\n",
       "      <th>_c3</th>\n",
       "      <th>_c4</th>\n",
       "      <th>_c5</th>\n",
       "      <th>_c6</th>\n",
       "      <th>_c7</th>\n",
       "      <th>_c8</th>\n",
       "      <th>_c9</th>\n",
       "      <th>...</th>\n",
       "      <th>_c51</th>\n",
       "      <th>_c52</th>\n",
       "      <th>_c53</th>\n",
       "      <th>_c54</th>\n",
       "      <th>_c55</th>\n",
       "      <th>_c56</th>\n",
       "      <th>_c57</th>\n",
       "      <th>_c58</th>\n",
       "      <th>_c59</th>\n",
       "      <th>_c60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _c0     _c1     _c2     _c3     _c4     _c5     _c6     _c7     _c8  \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "        _c9  ...    _c51    _c52    _c53    _c54    _c55    _c56    _c57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "       _c58    _c59 _c60  \n",
       "0    0.0090  0.0032    R  \n",
       "1    0.0052  0.0044    R  \n",
       "2    0.0095  0.0078    R  \n",
       "3    0.0040  0.0117    R  \n",
       "4    0.0107  0.0094    R  \n",
       "..      ...     ...  ...  \n",
       "203  0.0193  0.0157    M  \n",
       "204  0.0062  0.0067    M  \n",
       "205  0.0077  0.0031    M  \n",
       "206  0.0036  0.0048    M  \n",
       "207  0.0061  0.0115    M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.toPandas()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd78d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# X = shuffled_df.iloc[:, :-1].values\n",
    "# y = shuffled_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "78b06b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "      <th>_c2</th>\n",
       "      <th>_c3</th>\n",
       "      <th>_c4</th>\n",
       "      <th>_c5</th>\n",
       "      <th>_c6</th>\n",
       "      <th>_c7</th>\n",
       "      <th>_c8</th>\n",
       "      <th>_c9</th>\n",
       "      <th>...</th>\n",
       "      <th>_c51</th>\n",
       "      <th>_c52</th>\n",
       "      <th>_c53</th>\n",
       "      <th>_c54</th>\n",
       "      <th>_c55</th>\n",
       "      <th>_c56</th>\n",
       "      <th>_c57</th>\n",
       "      <th>_c58</th>\n",
       "      <th>_c59</th>\n",
       "      <th>_c60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.3127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.2294</td>\n",
       "      <td>0.2176</td>\n",
       "      <td>0.2033</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0701</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.1618</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0587</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>0.1498</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>0.2352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _c0     _c1     _c2     _c3     _c4     _c5     _c6     _c7     _c8  \\\n",
       "0    0.0305  0.0363  0.0214  0.0227  0.0456  0.0665  0.0939  0.0972  0.2535   \n",
       "1    0.0298  0.0615  0.0650  0.0921  0.1615  0.2294  0.2176  0.2033  0.1459   \n",
       "2    0.0139  0.0222  0.0089  0.0108  0.0215  0.0136  0.0659  0.0954  0.0786   \n",
       "3    0.0181  0.0146  0.0026  0.0141  0.0421  0.0473  0.0361  0.0741  0.1398   \n",
       "4    0.0411  0.0277  0.0604  0.0525  0.0489  0.0385  0.0611  0.1117  0.1237   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0331  0.0423  0.0474  0.0818  0.0835  0.0756  0.0374  0.0961  0.0548   \n",
       "204  0.0124  0.0433  0.0604  0.0449  0.0597  0.0355  0.0531  0.0343  0.1052   \n",
       "205  0.0260  0.0192  0.0254  0.0061  0.0352  0.0701  0.1263  0.1080  0.1523   \n",
       "206  0.0394  0.0420  0.0446  0.0551  0.0597  0.1416  0.0956  0.0802  0.1618   \n",
       "207  0.0587  0.1210  0.1268  0.1498  0.1436  0.0561  0.0832  0.0672  0.1372   \n",
       "\n",
       "        _c9  ...    _c51    _c52    _c53    _c54    _c55    _c56    _c57  \\\n",
       "0    0.3127  ...  0.0200  0.0070  0.0070  0.0086  0.0089  0.0074  0.0042   \n",
       "1    0.0852  ...  0.0031  0.0153  0.0071  0.0212  0.0076  0.0152  0.0049   \n",
       "2    0.1015  ...  0.0062  0.0072  0.0113  0.0012  0.0022  0.0025  0.0059   \n",
       "3    0.1045  ...  0.0223  0.0255  0.0145  0.0233  0.0041  0.0018  0.0048   \n",
       "4    0.2300  ...  0.0217  0.0038  0.0019  0.0065  0.0132  0.0108  0.0050   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0193  ...  0.0078  0.0174  0.0176  0.0038  0.0129  0.0066  0.0044   \n",
       "204  0.2120  ...  0.0083  0.0057  0.0174  0.0188  0.0054  0.0114  0.0196   \n",
       "205  0.1630  ...  0.0118  0.0120  0.0051  0.0070  0.0015  0.0035  0.0008   \n",
       "206  0.2558  ...  0.0146  0.0040  0.0114  0.0032  0.0062  0.0101  0.0068   \n",
       "207  0.2352  ...  0.0331  0.0111  0.0088  0.0158  0.0122  0.0038  0.0101   \n",
       "\n",
       "       _c58    _c59 _c60  \n",
       "0    0.0055  0.0021    1  \n",
       "1    0.0200  0.0073    0  \n",
       "2    0.0039  0.0048    0  \n",
       "3    0.0089  0.0085    0  \n",
       "4    0.0085  0.0044    1  \n",
       "..      ...     ...  ...  \n",
       "203  0.0134  0.0092    1  \n",
       "204  0.0147  0.0062    0  \n",
       "205  0.0044  0.0077    0  \n",
       "206  0.0053  0.0087    1  \n",
       "207  0.0228  0.0124    1  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36e83050",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df['_c60'] = (shuffled_df['_c60'] == 'M').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68734d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ad0fb242",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_samples = len(shuffled_df)\n",
    "index_80th = round(number_samples * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "96f935ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = shuffled_df.iloc[0:index_80th]\n",
    "test_data = shuffled_df.iloc[index_80th:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4a9b5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data['_c60'].to_numpy()\n",
    "train_features = train_data.drop(columns=['_c60'])\n",
    "test_label = test_data['_c60'].to_numpy()\n",
    "test_features = test_data.drop(columns=['_c60'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8ce00b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = list(train_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e6cea405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6794ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    learning_rate: float,\n",
    "    input_features: list[str],\n",
    "    metrics: list[keras.metrics.Metric],\n",
    ") -> keras.Model:\n",
    "    \"\"\"Create and compile a simple binary classification model.\"\"\"\n",
    "    model_inputs = [\n",
    "        keras.Input(name=feature, shape=(1,)) for feature in input_features\n",
    "    ]\n",
    "    concatenated_inputs = keras.layers.Concatenate()(model_inputs)\n",
    "\n",
    "    model_output = keras.layers.Dense(\n",
    "        units=1,\n",
    "        name='dense_layer',\n",
    "        activation=keras.activations.sigmoid\n",
    "    )(concatenated_inputs)\n",
    "\n",
    "    model = keras.Model(inputs=model_inputs, outputs=model_output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(learning_rate),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: keras.Model,\n",
    "    dataset: pd.DataFrame,\n",
    "    labels: np.ndarray,\n",
    "    input_features: list[str],\n",
    "    batch_size: int,\n",
    "    number_epochs: int,\n",
    "    experiment_name: str = \"default_experiment\"\n",
    ") -> dict:\n",
    "    \"\"\"Train the given Keras model on the provided dataset and labels.\"\"\"\n",
    "\n",
    "    # Prepare features dictionary\n",
    "    features = {\n",
    "        feature_name: np.array(dataset[feature_name], dtype=np.float32)\n",
    "        for feature_name in input_features\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        x=features,\n",
    "        y=labels,\n",
    "        batch_size=batch_size,\n",
    "        epochs=number_epochs,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Return experiment results\n",
    "    return {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"model\": model,\n",
    "        \"epochs_run\": history.epoch,\n",
    "        \"metrics_history\": pd.DataFrame(history.history)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d955a19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.5367 - auc: 0.5344 - loss: 0.6947 - precision: 0.5314 - recall: 1.0000 \n",
      "Epoch 2/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5514 - auc: 0.5402 - loss: 0.6910 - precision: 0.5395 - recall: 1.0000\n",
      "Epoch 3/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5628 - auc: 0.5534 - loss: 0.6890 - precision: 0.5458 - recall: 1.0000\n",
      "Epoch 4/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5815 - auc: 0.5540 - loss: 0.6875 - precision: 0.5567 - recall: 1.0000\n",
      "Epoch 5/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6043 - auc: 0.5622 - loss: 0.6862 - precision: 0.5709 - recall: 0.9922\n",
      "Epoch 6/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6076 - auc: 0.5686 - loss: 0.6850 - precision: 0.5736 - recall: 0.9845\n",
      "Epoch 7/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6002 - auc: 0.5654 - loss: 0.6839 - precision: 0.5702 - recall: 0.9706\n",
      "Epoch 8/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6002 - auc: 0.5713 - loss: 0.6829 - precision: 0.5707 - recall: 0.9628\n",
      "Epoch 9/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5929 - auc: 0.5806 - loss: 0.6820 - precision: 0.5672 - recall: 0.9489\n",
      "Epoch 10/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5929 - auc: 0.5898 - loss: 0.6810 - precision: 0.5684 - recall: 0.9350\n",
      "Epoch 11/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6043 - auc: 0.5959 - loss: 0.6801 - precision: 0.5759 - recall: 0.9350\n",
      "Epoch 12/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6116 - auc: 0.5984 - loss: 0.6792 - precision: 0.5810 - recall: 0.9350\n",
      "Epoch 13/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6149 - auc: 0.6101 - loss: 0.6783 - precision: 0.5840 - recall: 0.9272\n",
      "Epoch 14/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6196 - auc: 0.6168 - loss: 0.6775 - precision: 0.5905 - recall: 0.8994\n",
      "Epoch 15/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6270 - auc: 0.6186 - loss: 0.6766 - precision: 0.5960 - recall: 0.8994\n",
      "Epoch 16/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6343 - auc: 0.6250 - loss: 0.6757 - precision: 0.6016 - recall: 0.8994\n",
      "Epoch 17/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6417 - auc: 0.6300 - loss: 0.6749 - precision: 0.6073 - recall: 0.8994\n",
      "Epoch 18/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6497 - auc: 0.6340 - loss: 0.6740 - precision: 0.6136 - recall: 0.8994\n",
      "Epoch 19/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6497 - auc: 0.6454 - loss: 0.6732 - precision: 0.6136 - recall: 0.8994\n",
      "Epoch 20/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6531 - auc: 0.6552 - loss: 0.6723 - precision: 0.6175 - recall: 0.8916 \n",
      "Epoch 21/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6531 - auc: 0.6615 - loss: 0.6715 - precision: 0.6175 - recall: 0.8916\n",
      "Epoch 22/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6457 - auc: 0.6654 - loss: 0.6706 - precision: 0.6138 - recall: 0.8777\n",
      "Epoch 23/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6604 - auc: 0.6663 - loss: 0.6698 - precision: 0.6235 - recall: 0.8916\n",
      "Epoch 24/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6678 - auc: 0.6691 - loss: 0.6690 - precision: 0.6297 - recall: 0.8916\n",
      "Epoch 25/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6678 - auc: 0.6777 - loss: 0.6681 - precision: 0.6297 - recall: 0.8916\n",
      "Epoch 26/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6678 - auc: 0.6827 - loss: 0.6673 - precision: 0.6297 - recall: 0.8916\n",
      "Epoch 27/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6718 - auc: 0.6897 - loss: 0.6664 - precision: 0.6331 - recall: 0.8916\n",
      "Epoch 28/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6718 - auc: 0.6954 - loss: 0.6656 - precision: 0.6331 - recall: 0.8916\n",
      "Epoch 29/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6905 - auc: 0.7044 - loss: 0.6648 - precision: 0.6480 - recall: 0.8994\n",
      "Epoch 30/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6905 - auc: 0.7090 - loss: 0.6640 - precision: 0.6480 - recall: 0.8994\n",
      "Epoch 31/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6905 - auc: 0.7189 - loss: 0.6631 - precision: 0.6480 - recall: 0.8994\n",
      "Epoch 32/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6905 - auc: 0.7217 - loss: 0.6623 - precision: 0.6480 - recall: 0.8994\n",
      "Epoch 33/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6978 - auc: 0.7236 - loss: 0.6615 - precision: 0.6546 - recall: 0.8994\n",
      "Epoch 34/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7018 - auc: 0.7247 - loss: 0.6607 - precision: 0.6566 - recall: 0.9071\n",
      "Epoch 35/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7132 - auc: 0.7276 - loss: 0.6599 - precision: 0.6670 - recall: 0.9071\n",
      "Epoch 36/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7206 - auc: 0.7320 - loss: 0.6590 - precision: 0.6740 - recall: 0.9071\n",
      "Epoch 37/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7319 - auc: 0.7358 - loss: 0.6582 - precision: 0.6811 - recall: 0.9210\n",
      "Epoch 38/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7319 - auc: 0.7373 - loss: 0.6574 - precision: 0.6811 - recall: 0.9210\n",
      "Epoch 39/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7319 - auc: 0.7434 - loss: 0.6566 - precision: 0.6811 - recall: 0.9210\n",
      "Epoch 40/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7393 - auc: 0.7439 - loss: 0.6558 - precision: 0.6882 - recall: 0.9210\n",
      "Epoch 41/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7393 - auc: 0.7489 - loss: 0.6550 - precision: 0.6882 - recall: 0.9210\n",
      "Epoch 42/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7393 - auc: 0.7466 - loss: 0.6542 - precision: 0.6882 - recall: 0.9210\n",
      "Epoch 43/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7466 - auc: 0.7512 - loss: 0.6534 - precision: 0.6956 - recall: 0.9210\n",
      "Epoch 44/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7506 - auc: 0.7539 - loss: 0.6526 - precision: 0.6995 - recall: 0.9210\n",
      "Epoch 45/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7506 - auc: 0.7599 - loss: 0.6518 - precision: 0.6995 - recall: 0.9210\n",
      "Epoch 46/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7506 - auc: 0.7595 - loss: 0.6511 - precision: 0.6995 - recall: 0.9210\n",
      "Epoch 47/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7506 - auc: 0.7662 - loss: 0.6503 - precision: 0.6995 - recall: 0.9210\n",
      "Epoch 48/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7506 - auc: 0.7697 - loss: 0.6495 - precision: 0.6995 - recall: 0.9210\n",
      "Epoch 49/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7580 - auc: 0.7729 - loss: 0.6487 - precision: 0.7026 - recall: 0.9350\n",
      "Epoch 50/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7580 - auc: 0.7725 - loss: 0.6479 - precision: 0.7026 - recall: 0.9350\n",
      "Epoch 51/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7580 - auc: 0.7750 - loss: 0.6472 - precision: 0.7026 - recall: 0.9350\n",
      "Epoch 52/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7580 - auc: 0.7759 - loss: 0.6464 - precision: 0.7026 - recall: 0.9350\n",
      "Epoch 53/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7580 - auc: 0.7782 - loss: 0.6456 - precision: 0.7026 - recall: 0.9350\n",
      "Epoch 54/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7580 - auc: 0.7814 - loss: 0.6449 - precision: 0.7026 - recall: 0.9350\n",
      "Epoch 55/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7506 - auc: 0.7834 - loss: 0.6441 - precision: 0.6953 - recall: 0.9350\n",
      "Epoch 56/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7506 - auc: 0.7859 - loss: 0.6433 - precision: 0.6953 - recall: 0.9350\n",
      "Epoch 57/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7433 - auc: 0.7892 - loss: 0.6426 - precision: 0.6881 - recall: 0.9350\n",
      "Epoch 58/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7506 - auc: 0.7876 - loss: 0.6418 - precision: 0.6953 - recall: 0.9350\n",
      "Epoch 59/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7506 - auc: 0.7895 - loss: 0.6411 - precision: 0.6953 - recall: 0.9350\n",
      "Epoch 60/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7506 - auc: 0.7944 - loss: 0.6403 - precision: 0.6953 - recall: 0.9350\n"
     ]
    }
   ],
   "source": [
    "classification_threshold=0.5\n",
    "learning_rate=0.001\n",
    "number_epochs=60\n",
    "batch_size=100\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.BinaryAccuracy(\n",
    "        name='accuracy', threshold=classification_threshold\n",
    "    ),\n",
    "    keras.metrics.Precision(\n",
    "        name='precision', thresholds=classification_threshold\n",
    "    ),\n",
    "    keras.metrics.Recall(\n",
    "        name='recall', thresholds=classification_threshold\n",
    "    ),\n",
    "    keras.metrics.AUC(num_thresholds=100, name='auc'),\n",
    "]\n",
    "\n",
    "# Establish the model's topography.\n",
    "model = create_model(learning_rate, input_features, metrics)\n",
    "\n",
    "# Train the model on the training set.\n",
    "experiment = train_model(\n",
    "    model,train_features, train_label, input_features, batch_size, number_epochs, 'baseline'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eec19d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "15aba8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x203452cf890>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(experiment['epochs_run'], experiment['metrics_history']['accuracy'], label = 'accuracy')\n",
    "plt.plot(experiment['epochs_run'], experiment['metrics_history']['auc'], label = 'auc')\n",
    "plt.plot(experiment['epochs_run'], experiment['metrics_history']['loss'], label = 'loss')\n",
    "plt.plot(experiment['epochs_run'], experiment['metrics_history']['recall'], label = 'recall')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eda7b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_dict = {\n",
    "    feature_name: np.array(test_features[feature_name], dtype=np.float32)\n",
    "    for feature_name in input_features\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8f6888a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step - accuracy: 0.7619 - auc: 0.7753 - loss: 0.6416 - precision: 0.7586 - recall: 0.8800\n"
     ]
    }
   ],
   "source": [
    "accuracy_test, auc_test, loss_test, precision_test, recall_test = experiment['model'].evaluate(x=test_features_dict, y=test_label, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "583a5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train, auc_train, loss_train, precision_train, recall_train = list(experiment['metrics_history'].to_numpy()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fbc8e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Metrics between Train and test\n",
      "-------------\n",
      "Train Accuracy 0.741\n",
      "Test Accuracy 0.6416\n",
      "-------------\n",
      "Train AUC 0.7927\n",
      "Test AUC 0.7619\n",
      "-------------\n",
      "Train Loss 0.6404\n",
      "Test Loss 0.7586\n",
      "-------------\n",
      "Train Precision 0.6838\n",
      "Test Precision 0.88\n",
      "-------------\n",
      "Train Recall 0.9302\n",
      "Test Recall 0.7753\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "print('Comparing Metrics between Train and test')\n",
    "print('-------------')\n",
    "print('Train Accuracy', round(float(accuracy_train),4))\n",
    "print('Test Accuracy', round(float(accuracy_test),4))\n",
    "print('-------------')\n",
    "print('Train AUC', round(float(auc_train),4))\n",
    "print('Test AUC', round(float(auc_test),4))\n",
    "print('-------------')\n",
    "print('Train Loss', round(float(loss_train),4))\n",
    "print('Test Loss', round(float(loss_test),4))\n",
    "print('-------------')\n",
    "print('Train Precision', round(float(precision_train),4))\n",
    "print('Test Precision', round(float(precision_test),4))\n",
    "print('-------------')\n",
    "print('Train Recall', round(float(recall_train),4))\n",
    "print('Test Recall', round(float(recall_test),4))\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0300bcd",
   "metadata": {},
   "source": [
    "Using Normal Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a4357757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = shuffled_df.iloc[:, :-1].values\n",
    "y = shuffled_df.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "27102575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(random_state=0)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c9eff3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f3a250c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "810f3e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 10]\n",
      " [ 3 17]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6904761904761905"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
